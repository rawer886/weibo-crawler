# 设计原则

本文档说明微博爬虫的核心设计原则和实现策略。

## 核心原则

### 1. 数据完整性优先

**不浪费已返回的数据**

配置参数（如 `max_comments_per_post`）用于控制**请求次数/翻页次数**，而不是限制存储数量。

```python
# 配置示例
"max_comments_per_post": 10  # 期望获取 10 条评论（用于控制是否翻页）

# 实际行为
# - 如果一次请求返回 5 条 → 存储 5 条，不翻页
# - 如果一次请求返回 20 条 → 存储 20 条，不截断
```

**原则**：
- 已返回的数据全部保存
- 配置值只控制获取策略，不控制存储上限
- 避免浪费已消耗的请求

### 2. 减少请求，降低风控

**缓存策略**

| 数据类型 | 缓存策略 | 原因 |
|----------|----------|------|
| 博主信息 | 永久缓存（7天TTL） | 变化不频繁 |
| 微博列表（第一页） | **不缓存** | 需要检查新微博 |
| 微博列表（历史页） | **永久缓存** | 历史数据不会变化 |
| 微博详情 | 数据库去重 | 已入库的不再请求 |
| 评论 | 数据库去重 | 已入库的不再请求 |

**原则**：
- 历史数据永久缓存（MD5 key + JSON 文件）
- 最新数据实时检查
- 数据库自动去重，避免重复抓取

### 3. 智能断点续传

**增量抓取模式**

```python
# new 模式：抓取新微博
# - 从最新微博开始向前抓取
# - 遇到已入库的微博停止
# - 适合日常更新

# history 模式：抓取历史微博
# - 从数据库最老的微博继续向后
# - 直到达到时间范围限制
# - 适合首次抓取或补全历史

# all 模式：双向抓取（默认）
# - 先执行 new 模式（抓新的）
# - 再执行 history 模式（补历史）
# - 确保完整性
```

**原则**：
- 记录抓取边界（newest_mid / oldest_mid）
- 支持中断后继续
- 自动识别新旧数据

### 4. 时间范围限制

**限制历史范围**

```python
"max_days": 180  # 只抓取最近 180 天的微博
```

**原则**：
- 避免抓取过于久远的数据
- 减少无效请求
- 聚焦有价值的数据
- 到达时间边界自动停止

### 5. 评论抓取延迟

**等待评论稳定**

```python
"comment_delay_days": 3  # 微博发布 3 天后才抓评论
```

**原则**：
- 评论需要时间沉淀
- 热门评论在发布后几天才稳定
- 避免抓取不完整的评论
- 提高数据质量


## 风控策略

### 请求间隔

```python
"min_delay": 8,   # 最小间隔 8 秒
"max_delay": 30,  # 最大间隔 30 秒
```

**原则**：
- 随机延迟，模拟人类行为
- 间隔范围可配置
- 评论抓取使用专用延迟配置

### 登录保持

**Cookie 管理**：
- 首次手动登录
- 自动保存 cookies
- 每次运行验证登录状态
- 失效时提示重新登录

### 浏览器模式

```python
"headless": False  # 可见模式，方便调试和登录
```

**原则**：
- 支持有头/无头模式切换
- 开发调试时使用有头模式
- 生产环境可切换无头模式

## 数据组织

### 目录结构

```
data/
├── weibo.db          # 数据库（所有结构化数据）
├── cookies.json      # 登录状态
├── cache/            # API 响应缓存
├── images/           # 图片文件
│   └── {uid}/       # 按博主分类
│       └── {date}/  # 按日期分类
└── logs/             # 运行日志
```

**原则**：
- 代码和数据完全分离
- 数据按类型和来源组织
- 便于备份和迁移

### 数据库设计

**表关系**：
```
bloggers (博主) 1 ─────┐
                       │ 1:N
posts (微博)    N ─────┴─── uid
                       │
                       │ 1:N (mid)
comments (评论) N ─────┘
```

**原则**：
- 规范化设计
- 外键关联
- 索引优化（uid, mid, created_at, likes_count）
- 支持复杂查询

## 扩展性

### 模块化设计

```
crawler.py      # 爬虫核心逻辑
database.py     # 数据库操作
config.py       # 配置管理
main.py         # 主程序入口
scripts/        # 查询分析工具
tests/          # 测试工具
```

**原则**：
- 职责分离
- 易于维护
- 支持功能扩展
- 便于添加新工具

### 配置驱动

所有策略参数在 `config.py` 中集中配置：
- 博主列表
- 抓取参数
- 延迟策略
- 路径配置

**原则**：
- 配置与代码分离
- 修改配置无需改代码
- 支持多环境配置
- 参数有清晰注释

## 开发规范

### 日志记录

```python
logger.info()    # 重要操作（抓取进度）
logger.debug()   # 调试信息（详细过程）
logger.warning() # 可恢复错误（请求失败）
logger.error()   # 严重错误（程序异常）
```

### 错误处理

**原则**：
- 捕获可预期的异常
- 记录错误但不停止（单条失败）
- 优雅停止（Ctrl+C）
- 确保资源清理（浏览器关闭）

### 代码风格

- 清晰的函数命名
- 详细的文档字符串
- 合理的注释
- 避免魔法数字

## 性能优化

### 请求优化
- 使用移动端 API（更轻量）
- 缓存响应减少请求
- 批量处理数据

### 解析优化
- 直接定位元素（避免全页面遍历）
- 复用 Page 对象
- 合理的超时设置

### 存储优化
- 批量插入（事务）
- 索引优化
- JSON 字段存储复杂数据

## 总结

本项目遵循以下核心理念：

1. **数据为王** - 完整性优先，不浪费数据
2. **智能抓取** - 缓存+去重+断点续传
3. **风控友好** - 随机延迟+限制频率
4. **易于使用** - 配置驱动+自动化
5. **可维护性** - 模块化+文档完整
